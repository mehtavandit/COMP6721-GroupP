Epochs,Training Loss,Validation Loss
1,0.0,0.0
2,2.872165969623597,2.566585956416465
3,2.567411402157165,2.433414043583535
4,2.3690843055249835,1.8998459167950694
5,2.244441998679287,2.833370019810698
6,2.152377283733216,1.766453885097953
7,2.1124807395993837,3.733215936605767
8,2.0467752586396655,2.633281972265023
9,1.991470394012767,1.6667400396213956
10,1.9701188641866607,1.833149900946511
11,1.944309927360775,1.6665199207572088
12,1.9132731675104557,1.9333039841514417
13,1.8874642306845697,1.6667400396213956
14,1.8687541272287036,2.0
15,1.8563724411182039,1.6665199207572088
16,1.8329297820823245,1.8666079683028836
17,1.819832709663218,1.5333480079242792
18,1.808166409861325,2.0
19,1.7889610389610389,2.033237948492186
20,1.780761611270086,1.5333480079242792
21,1.7706911732335462,1.6999779881135813
22,1.7517609509134933,2.0666960158485583
23,1.737838432753687,1.9333039841514417
24,1.739984591679507,1.8666079683028836
25,1.7187981510015409,1.833149900946511
26,1.7023992956196345,1.5333480079242792
27,1.6923838872991415,2.0
28,1.6806625577812018,1.7999119524543252
29,1.6661897424609289,2.0
30,1.6542482940788026,1.1666299801893023
31,1.6382896764252697,1.3999559762271627
